{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466107fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2438834",
   "metadata": {},
   "source": [
    "# Data loading and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9836da",
   "metadata": {},
   "source": [
    "Since I was having problems with the ir_datasets library, I downloaded locally the dataset files from https://ciir.cs.umass.edu/downloads/Antique/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e86372",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "4b5124a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"C:\\Users\\filip\\Projects\\Neural_IR_Expansion\\Dataset\"\n",
    "\n",
    "antique_collection = os.path.join(dataset_path, \"antique-collection.txt\")\n",
    "docs_df_cols = ['answer_id', 'answer_text']\n",
    "docs = pd.read_csv(antique_collection, sep='\\t', header=None, names=docs_df_cols)\n",
    "\n",
    "antique_train_queries = os.path.join(dataset_path, \"antique-train-queries.txt\")\n",
    "train_queries_cols = [\"query_id\", \"query_text\"]\n",
    "train_queries = pd.read_csv(antique_train_queries, sep='\\t', header=None, names=train_queries_cols)\n",
    "\n",
    "antique_train_qrels = os.path.join(dataset_path, \"antique-train.qrel.txt\")\n",
    "train_qrels_cols = [\"query_id\", \"relevance_type\", \"answer_id\", \"relevance\"]\n",
    "train_qrels = pd.read_csv(antique_train_qrels, sep=r'\\s+', header=None, names=train_qrels_cols) # the sep handles the separation between columns \" \" and \"\\t\"\n",
    "\n",
    "antique_test_queries = os.path.join(dataset_path, \"antique-test-queries.txt\")\n",
    "test_queries_cols = [\"query_id\", \"query_text\"]\n",
    "test_queries = pd.read_csv(antique_test_queries, sep='\\t', header=None, names=test_queries_cols)\n",
    "\n",
    "antique_test_qrels = os.path.join(dataset_path, \"antique-test.qrel.txt\")\n",
    "test_qrels_cols = [\"query_id\", \"relevance_type\", \"answer_id\", \"relevance\"]\n",
    "test_qrels = pd.read_csv(antique_test_qrels, sep=r'\\s+', header=None, names=test_qrels_cols) # the sep handles the separation between columns \" \" and \"\\t\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b56b8",
   "metadata": {},
   "source": [
    "From the dataset readme, we know that the \"doc_id\" column contains two separate informations, so we can split the \"doc_id\" column to get the \"query_id\" and \"answer_n\" separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "1786eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[['query_id', 'answer_n']] = docs['answer_id'].str.split('_', expand=True)\n",
    "train_qrels[['query_id', 'answer_n']] = train_qrels['answer_id'].str.split('_', expand=True)\n",
    "test_qrels[['query_id', 'answer_n']] = test_qrels['answer_id'].str.split('_', expand=True)\n",
    "\n",
    "docs['query_id'] = docs['query_id'].astype(int)\n",
    "train_qrels['query_id'] = train_qrels['query_id'].astype(int)\n",
    "test_qrels['query_id'] = test_qrels['query_id'].astype(int)\n",
    "\n",
    "docs['answer_n'] = docs['answer_n'].astype(int)\n",
    "train_qrels['answer_n'] = train_qrels['answer_n'].astype(int)\n",
    "test_qrels['answer_n'] = test_qrels['answer_n'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bc65e7",
   "metadata": {},
   "source": [
    "Now, let's see how our data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "5c888e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs shape: (403458, 4)\n",
      "train_queries shape: (2426, 2)\n",
      "train_qrels shape: (27422, 5)\n",
      "test_queries shape: (200, 2)\n",
      "test_qrels shape: (6589, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"docs shape: {docs.shape}\")\n",
    "print(f\"train_queries shape: {train_queries.shape}\")\n",
    "print(f\"train_qrels shape: {train_qrels.shape}\")\n",
    "print(f\"test_queries shape: {test_queries.shape}\")\n",
    "print(f\"test_qrels shape: {test_qrels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffbf5e",
   "metadata": {},
   "source": [
    "### Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "81dc8ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_id      0\n",
      "answer_text    5\n",
      "query_id       0\n",
      "answer_n       0\n",
      "dtype: int64\n",
      "\n",
      "query_id      0\n",
      "query_text    0\n",
      "dtype: int64\n",
      "\n",
      "query_id          0\n",
      "relevance_type    0\n",
      "answer_id         0\n",
      "relevance         0\n",
      "answer_n          0\n",
      "dtype: int64\n",
      "\n",
      "query_id      0\n",
      "query_text    0\n",
      "dtype: int64\n",
      "\n",
      "query_id          0\n",
      "relevance_type    0\n",
      "answer_id         0\n",
      "relevance         0\n",
      "answer_n          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{docs.isnull().sum()}\\n\")\n",
    "print(f\"{train_queries.isnull().sum()}\\n\")\n",
    "print(f\"{train_qrels.isnull().sum()}\\n\")\n",
    "print(f\"{test_queries.isnull().sum()}\\n\")\n",
    "print(test_qrels.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581e563",
   "metadata": {},
   "source": [
    "We have 1 column in docs (\"text\") with 5 null values. It probably corresponds to some uploaded but empty answers by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "af4b2abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>query_id</th>\n",
       "      <th>answer_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>1940280_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940280</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31936</th>\n",
       "      <td>435733_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35357</th>\n",
       "      <td>3975689_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3975689</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140950</th>\n",
       "      <td>2677531_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2677531</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262306</th>\n",
       "      <td>493662_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>493662</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        answer_id answer_text  query_id  answer_n\n",
       "5378    1940280_3         NaN   1940280         3\n",
       "31936    435733_1         NaN    435733         1\n",
       "35357   3975689_3         NaN   3975689         3\n",
       "140950  2677531_4         NaN   2677531         4\n",
       "262306   493662_4         NaN    493662         4"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_nulls = docs[docs.isnull().any(axis=1)]\n",
    "docs_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "a6061555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>relevance_type</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>answer_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2677531</td>\n",
       "      <td>E0</td>\n",
       "      <td>2677531_4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id relevance_type  answer_id  relevance  answer_n\n",
       "0   2677531             E0  2677531_4          3         4"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_qrels = train_qrels.merge(docs_nulls[['query_id', 'answer_id']], on=['query_id', 'answer_id'])\n",
    "matching_qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb036517",
   "metadata": {},
   "source": [
    "Let's get rid of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "ea1dbe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>relevance_type</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>answer_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [query_id, relevance_type, answer_id, relevance, answer_n]\n",
       "Index: []"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_qrels = train_qrels[train_qrels['answer_id'] != \"2677531_4\"]\n",
    "\n",
    "matching_qrels = train_qrels.merge(docs_nulls[['query_id', 'answer_id']], on=['query_id', 'answer_id'])\n",
    "matching_qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa554e9",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "42bef66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows:\n",
      "\n",
      "docs: 0\n",
      "train_queries: 0\n",
      "train_qrels: 0\n",
      "test_queries: 0\n",
      "test_qrels: 35\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate rows:\\n\")\n",
    "print(\"docs:\", docs.duplicated().sum())\n",
    "print(\"train_queries:\", train_queries.duplicated().sum())\n",
    "print(\"train_qrels:\", train_qrels.duplicated().sum())\n",
    "print(\"test_queries:\", test_queries.duplicated().sum())\n",
    "print(\"test_qrels:\", test_qrels.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "ec8297ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>relevance_type</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>answer_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>144229</td>\n",
       "      <td>Q0</td>\n",
       "      <td>144229_5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>144229</td>\n",
       "      <td>Q0</td>\n",
       "      <td>144229_5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>229566</td>\n",
       "      <td>Q0</td>\n",
       "      <td>229566_0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>229566</td>\n",
       "      <td>Q0</td>\n",
       "      <td>229566_0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>230487</td>\n",
       "      <td>Q0</td>\n",
       "      <td>230487_0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>4169123</td>\n",
       "      <td>Q0</td>\n",
       "      <td>4169123_11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>4225209</td>\n",
       "      <td>Q0</td>\n",
       "      <td>4225209_3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>4225209</td>\n",
       "      <td>Q0</td>\n",
       "      <td>4225209_3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>4235114</td>\n",
       "      <td>Q0</td>\n",
       "      <td>4235114_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>4235114</td>\n",
       "      <td>Q0</td>\n",
       "      <td>4235114_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query_id relevance_type   answer_id  relevance  answer_n\n",
       "1351    144229             Q0    144229_5          1         5\n",
       "3525    144229             Q0    144229_5          1         5\n",
       "3248    229566             Q0    229566_0          2         0\n",
       "4376    229566             Q0    229566_0          2         0\n",
       "1546    230487             Q0    230487_0          4         0\n",
       "...        ...            ...         ...        ...       ...\n",
       "5387   4169123             Q0  4169123_11          1        11\n",
       "1870   4225209             Q0   4225209_3          2         3\n",
       "3090   4225209             Q0   4225209_3          2         3\n",
       "1851   4235114             Q0   4235114_1          1         1\n",
       "2968   4235114             Q0   4235114_1          1         1\n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_qrels_duplicates = test_qrels[test_qrels.duplicated(keep=False)].sort_values(by=test_qrels.columns.tolist())\n",
    "test_qrels_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125a94e5",
   "metadata": {},
   "source": [
    "Let's drop the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "238fec42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_qrels duplicates: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6554"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_qrels.drop_duplicates(inplace=True)\n",
    "print(\"test_qrels duplicates:\", test_qrels.duplicated().sum())\n",
    "len(test_qrels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478bda61",
   "metadata": {},
   "source": [
    "### Merge the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967dad83",
   "metadata": {},
   "source": [
    "Now we want to merge the datasets in order to have only two for train and test (we will extract also a validation set from the train).\n",
    "\n",
    "So, let's check if all the query_id's in the query df's for train and test appear also in the qrels df's, and if so we can start merging these two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "4b193e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All train_queries in train_qrels? True\n",
      "Train qrels query_ids NOT in train_queries: 0\n"
     ]
    }
   ],
   "source": [
    "# Train: Check if all query_ids in train_queries are in train_qrels\n",
    "train_queries_in_qrels = set(train_queries['query_id']).issubset(set(train_qrels['query_id']))\n",
    "print(\"All train_queries in train_qrels?\", train_queries_in_qrels)\n",
    "\n",
    "# Check if there are query_ids in qrels not in queries\n",
    "train_qrels_extra_queries = set(train_qrels['query_id']) - set(train_queries['query_id'])\n",
    "print(\"Train qrels query_ids NOT in train_queries:\", len(train_qrels_extra_queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "276fc32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test_queries in test_qrels? True\n",
      "Test qrels query_ids NOT in test_queries: 3676\n"
     ]
    }
   ],
   "source": [
    "# Train: Check if all query_ids in train_queries are in train_qrels\n",
    "test_queries_in_qrels = set(test_queries['query_id']).issubset(set(test_qrels['query_id']))\n",
    "print(\"All test_queries in test_qrels?\", test_queries_in_qrels)\n",
    "\n",
    "# Check if there are query_ids in qrels not in queries\n",
    "test_qrels_extra_queries = set(test_qrels['query_id']) - set(test_queries['query_id'])\n",
    "print(\"Test qrels query_ids NOT in test_queries:\", len(test_qrels_extra_queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8088e170",
   "metadata": {},
   "source": [
    "We have some queries in the test qrels df that are not present in the test queries df, so let's drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "ffe9600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6554\n",
      "2181\n",
      "Test qrels query_ids NOT in test_queries: 0\n"
     ]
    }
   ],
   "source": [
    "print(len(test_qrels))\n",
    "test_qrels = test_qrels[test_qrels['query_id'].isin(test_queries['query_id'])]\n",
    "print(len(test_qrels))\n",
    "\n",
    "test_qrels_extra_queries = set(test_qrels['query_id']) - set(test_queries['query_id'])\n",
    "print(\"Test qrels query_ids NOT in test_queries:\", len(test_qrels_extra_queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce97184c",
   "metadata": {},
   "source": [
    "Now we can merge queries and qrels for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "efb616e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged = pd.merge(train_qrels, train_queries, on='query_id', how='inner')\n",
    "test_merged = pd.merge(test_qrels, test_queries, on='query_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "8301df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_merged shape: (27421, 6)\n",
      "test_merged shape: (2181, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_merged shape: {train_merged.shape}\")\n",
    "print(f\"test_merged shape: {test_merged.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a4741a",
   "metadata": {},
   "source": [
    "Check if all answer_ids in the merged DataFrames are in docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "7e042f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: answer_ids not in docs: 16\n",
      "Test: answer_ids not in docs: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for train\n",
    "missing_train_answers = ~train_merged['answer_id'].isin(docs['answer_id'])\n",
    "print(\"Train: answer_ids not in docs:\", missing_train_answers.sum())\n",
    "\n",
    "# Check for test\n",
    "missing_test_answers = ~test_merged['answer_id'].isin(docs['answer_id'])\n",
    "print(\"Test: answer_ids not in docs:\", missing_test_answers.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da64b997",
   "metadata": {},
   "source": [
    "Let's drop rows with missing answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "d15992b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27405"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged = train_merged[train_merged['answer_id'].isin(docs['answer_id'])]\n",
    "len(train_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "cde8406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final merge\n",
    "train_val_df = pd.merge(train_merged, docs[['answer_id', 'answer_text']], on='answer_id', how='inner')\n",
    "test_df = pd.merge(test_merged, docs[['answer_id', 'answer_text']], on='answer_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a1e52",
   "metadata": {},
   "source": [
    "Now we want also to extract the validation set from train_df. We will do a 10% split.  \n",
    "\n",
    "Splitting by query_id guarantees no overlap of queries between train and validation, altho it won't be a perfect 10% split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "05bb131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split shape: (24685, 7)\n",
      "Validation split shape: (2720, 7)\n",
      "Test split shape: (2181, 7)\n"
     ]
    }
   ],
   "source": [
    "unique_queries = train_val_df['query_id'].unique()\n",
    "split_idx = int(len(unique_queries) * 0.1)  # 10% for validation\n",
    "\n",
    "# Split query IDs\n",
    "val_queries = unique_queries[:split_idx]\n",
    "train_queries = unique_queries[split_idx:]\n",
    "\n",
    "# Split the dataframe accordingly\n",
    "train_df = train_val_df[train_val_df['query_id'].isin(train_queries)].reset_index(drop=True)\n",
    "val_df = train_val_df[train_val_df['query_id'].isin(val_queries)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train split shape: {train_df.shape}\")\n",
    "print(f\"Validation split shape: {val_df.shape}\")\n",
    "print(f\"Test split shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "80f78bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_id          0\n",
      "relevance_type    0\n",
      "answer_id         0\n",
      "relevance         0\n",
      "answer_n          0\n",
      "query_text        0\n",
      "answer_text       0\n",
      "dtype: int64\n",
      "query_id          0\n",
      "relevance_type    0\n",
      "answer_id         0\n",
      "relevance         0\n",
      "answer_n          0\n",
      "query_text        0\n",
      "answer_text       0\n",
      "dtype: int64\n",
      "query_id          0\n",
      "relevance_type    0\n",
      "answer_id         0\n",
      "relevance         0\n",
      "answer_n          0\n",
      "query_text        0\n",
      "answer_text       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())\n",
    "print(val_df.isnull().sum())\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588c125",
   "metadata": {},
   "source": [
    "We have our clean data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neural_IR_Expansion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
